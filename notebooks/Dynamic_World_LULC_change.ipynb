{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from pathlib import Path\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using Google Earth Engine (GEE) for the first time\n",
    "# or if you encounter an \"Earth Engine not initialized\" error.\n",
    "\n",
    "# ee.Authenticate()  # Run once to authenticate your Google account (only needed for new environments)\n",
    "# ee.Initialize()    # Run every session to initialize the Earth Engine API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Set the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1. Loading the variables for selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dropdown widget configuration\n",
    "parks = [\n",
    "    'Addo Elephant', 'Agulhas', 'Augrabies Falls', 'Bontebok', 'Camdeboo', 'Garden Route',\n",
    "    'Golden Gate Highlands', 'Graspan', 'Groenkloof', 'Kalahari Gemsbok', 'Karoo', 'Kruger',\n",
    "    'Mapungubwe', 'Marakele', 'Mokala', 'Mountain Zebra', 'Namaqua', 'Richtersveld',\n",
    "    'Table Mountain', 'Tankwa Karoo', 'West Coast'\n",
    "]\n",
    "\n",
    "years = [str(y) for y in range(2016, 2024)]\n",
    "\n",
    "# Define dropdowns\n",
    "park_dropdown = widgets.Dropdown(options=parks, value='Addo Elephant', description='Park:')\n",
    "year_start_dropdown = widgets.Dropdown(options=years, value='2016', description='Start Year:')\n",
    "year_end_dropdown = widgets.Dropdown(options=years, value='2023', description='End Year:')\n",
    "\n",
    "# Store selections in a dictionary instead of global variables\n",
    "selection = {\n",
    "    \"Park\": park_dropdown.value,\n",
    "    \"Starting Year\": int(year_start_dropdown.value),\n",
    "    \"Ending Year\": int(year_end_dropdown.value)\n",
    "}\n",
    "\n",
    "# Generic update function\n",
    "def update_selection(change, key):\n",
    "    selection[key] = int(change.new) if key != \"Park\" else change.new\n",
    "\n",
    "# Attach event listeners\n",
    "park_dropdown.observe(lambda change: update_selection(change, \"Park\"), names='value')\n",
    "year_start_dropdown.observe(lambda change: update_selection(change, \"Starting Year\"), names='value')\n",
    "year_end_dropdown.observe(lambda change: update_selection(change, \"Ending Year\"), names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2. Variable parameters (Please select from the list below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fca072345604d1c860ae355109e2790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Park:', options=('Addo Elephant', 'Agulhas', 'Augrabies Falls', 'Bontebok', 'Camdeboo', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd7357fe3c94e48a1eeec228f6085e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Start Year:', options=('2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f23b1c45a748feba6cfcbd461f63f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='End Year:', index=7, options=('2016', '2017', '2018', '2019', '2020', '2021', '2022', '2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Please choose parameters from the dropdown list below\n",
    "display(park_dropdown, year_start_dropdown, year_end_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3. Static parameters (Based on selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to set any variables\n",
    "# Calculate the list of years from starting_year to ending_year, inclusive\n",
    "Years = list(range(starting_year, ending_year + 1))\n",
    "\n",
    "#Setting the properties for the layer to represent the data on the map and for color coding later on\n",
    "dw_vis = {\"min\": 0, \"max\": 8, \"palette\": [\"#419BDF\", \"#397D49\", \"#88B053\", \"#7A87C6\", \"#E49635\", \"#DFC35A\", \"#C4281B\", \"#A59B8F\", \"#B39FE1\"]}\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['water', 'trees', 'grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built', 'bare_soil', 'snow_and_ice']\n",
    "\n",
    "# Load configuration settings\n",
    "config_path = Path(\"config.json\")  # Adjust for notebooks\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Set base path dynamically from config.json\n",
    "base_path = Path(config[\"base_path\"])\n",
    "\n",
    "# Defining the different sub-areas\n",
    "# CPA: Catchment Protected Area, VPA: Viewshed Protected Area, PNA: Priority Natural Areas, Parks: Park boundaries itself\n",
    "potential_sub_areas = ['CPA', 'VPA', 'PNA', 'Parks', 'Dissolved']\n",
    "\n",
    "# Initialize a list to store only the sub-areas with available shapefiles\n",
    "sub_areas = []\n",
    "\n",
    "# Check each sub-area for an available shapefile\n",
    "for sub_area in potential_sub_areas:\n",
    "    shapefile_path = os.path.join(base_path, sub_area, f'{Park}_{sub_area}.shp')\n",
    "    if os.path.exists(shapefile_path):\n",
    "        sub_areas.append(sub_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Initiate the map (set credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will prompt you to authorize via Earth Engine\n",
    "# Data plotted later in notebook will be displayed on this map\n",
    "Map = geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Loading the data (server-side) according to above set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Loading the data in Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store results per sub-area and per year\n",
    "results_per_area_and_year = {}\n",
    "\n",
    "# Assuming 'fishnet' is already created as per the previous code snippet\n",
    "for sub_area in sub_areas:\n",
    "    # Update the path based on the new structure and sub-area\n",
    "    park_sub_shp = fr'C:\\Users\\grobler\\Desktop\\Personal\\Masters\\Data\\GIS\\Parks_buffer\\sub_areas\\{sub_area}\\{Park}_{sub_area}.shp'\n",
    "    park_sub = geemap.shp_to_ee(park_sub_shp)\n",
    "    geometry = park_sub.geometry()    \n",
    "\n",
    "    # Initialize a dictionary for this sub-area to store dw_class objects per year\n",
    "    dw_classes_per_year = {}\n",
    "\n",
    "    for Year in Years:\n",
    "        start_date = f'{Year}-01-01'\n",
    "        end_date = f'{Year}-12-31'\n",
    "\n",
    "        # This loads the DW dataset according to parameters set above\n",
    "        dw_classes = geemap.dynamic_world(geometry, start_date, end_date, return_type='class', reducer='mode')\n",
    "        dw_class = dw_classes.clip(geometry)\n",
    "\n",
    "        # Store the dw_class in the dictionary with the year as the key\n",
    "        dw_classes_per_year[Year] = dw_class\n",
    "\n",
    "    # Store the results for this sub-area\n",
    "    results_per_area_and_year[sub_area] = dw_classes_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2. Plotting the data on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please see the map above for results\n",
    "# Recommended to plot individual samples using the following logic:\n",
    "Map.addLayer(results_per_area_and_year['Dissolved'][2016], dw_vis, 'Exmaple LULC plot', False)\n",
    "\n",
    "# Warning! This step takes long (use only when required)\n",
    "#for sub_area, years_data in results_per_area_and_year.items():\n",
    "#    for year, dw_class in years_data.items():\n",
    "#        layer_name = f'DW {sub_area} for {year}'\n",
    "#        Map.addLayer(dw_class, dw_vis, layer_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Creating the \"Fisnet\" (avoid API overload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.1. Load dissolved buffers to get entire extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dissolved park AND buffer file\n",
    "parks_shp = r'C:\\Users\\grobler\\Desktop\\Personal\\Masters\\Data\\GIS\\Parks_buffer\\dissolved_all_buffers_FINAL.shp'\n",
    "parks = geemap.shp_to_ee(parks_shp)\n",
    "#Map.addLayer(parks, {}, 'dissolved_all_buffers_FINAL') #Can uncomment if you want to show all parks on the map above\n",
    "\n",
    "#Some parks don't fall good in fishnet and should consider \n",
    "park_dissolved_shp = fr'C:\\Users\\grobler\\Desktop\\Personal\\Masters\\Data\\GIS\\Parks_buffer\\sub_areas\\Dissolved\\{Park}_Dissolved.shp'\n",
    "park_dissovled = geemap.shp_to_ee(park_sub_shp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.2. Create a \"Fishnet\" from above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply the fishnet before processing large areas you have to determine the maximum extent\n",
    "# Get the bounding box as a geometry object\n",
    "bounding_box = parks.geometry().bounds()\n",
    "#bounding_box = park_dissovled.geometry().bounds()\n",
    "\n",
    "# Use getInfo() to convert the bounding box into a dictionary\n",
    "bounding_box_info = bounding_box.getInfo()\n",
    "\n",
    "# Extract the coordinates of the bounding box\n",
    "# This accesses the first and only element of the coordinates list, which represents the bounding box polygon.\n",
    "coords = bounding_box_info['coordinates'][0]  \n",
    "\n",
    "# Extract min and max longitude and latitude\n",
    "min_lon = coords[0][0]  # Minimum longitude\n",
    "min_lat = coords[0][1]  # Minimum latitude\n",
    "max_lon = coords[2][0]  # Maximum longitude\n",
    "max_lat = coords[2][1]  # Maximum latitude\n",
    "\n",
    "# Create a BBox object with these coordinates\n",
    "region = ee.Geometry.BBox(min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "# This creates the grid to overly the region/area of interest\n",
    "fishnet = geemap.fishnet(region, h_interval=1.0, v_interval=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.3. Pre-calculate the sub-area and fishnet intersections (windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store window geometries for each sub-area\n",
    "window_geometries_per_sub_area = {}\n",
    "\n",
    "for sub_area in sub_areas:\n",
    "    park_sub_shp = fr'C:\\Users\\grobler\\Desktop\\Personal\\Masters\\Data\\GIS\\Parks_buffer\\sub_areas\\{sub_area}\\{Park}_{sub_area}.shp'\n",
    "    park_sub = geemap.shp_to_ee(park_sub_shp)\n",
    "    geometry = park_sub.geometry()\n",
    "    \n",
    "    # Calculate intersected features for this sub-area\n",
    "    intersected_features = fishnet.map(lambda feature: ee.Feature(feature).intersection(geometry, ee.ErrorMargin(1)))\n",
    "    \n",
    "    # Initialize window geometries list\n",
    "    window_geometries = []\n",
    "    for feature in intersected_features.getInfo()['features']:\n",
    "        geom = ee.Geometry(feature['geometry'])\n",
    "        area = geom.area().getInfo()\n",
    "        if area > 1:\n",
    "            window_geometries.append(geom)\n",
    "    \n",
    "    # Store the window geometries for this sub-area\n",
    "    window_geometries_per_sub_area[sub_area] = window_geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to plot an example of the overlapping Fishnet windows and sub-areas\n",
    "# Define the style\n",
    "#style = {\"color\": \"ffff00ff\", \"fillColor\": \"00000000\"}\n",
    "\n",
    "# To convert the list to a feature collection for plotting\n",
    "#geometries_list = window_geometries_per_sub_area['CPA'] # Please specify a sub-area of interest to you here\n",
    "#features = [ee.Feature(geom) for geom in geometries_list]\n",
    "#feature_collection = ee.FeatureCollection(features)\n",
    "\n",
    "# To add the overlapping geometries of interest to the map\n",
    "#Map.addLayer(feature_collection.style(**style), {}, \"Window Geometries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to plot an example of the overlapping Fishnet windows and sub-areas\n",
    "# Define the style\n",
    "#style = {\"color\": \"ffff00ff\", \"fillColor\": \"00000000\"}\n",
    "\n",
    "# To convert the list to a feature collection for plotting\n",
    "#geometries_list = window_geometries_per_sub_area['CPA'] # Please specify a sub-area of interest to you here\n",
    "#features = [ee.Feature(geom) for geom in geometries_list]\n",
    "#feature_collection = ee.FeatureCollection(features)\n",
    "\n",
    "# To add the overlapping geometries of interest to the map\n",
    "#Map.addLayer(fishnet.style(**style), {}, \"Window Geometries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Calculate the number of pixels per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: This is the most time-consuming part of the script. But once all the data is derived the plotting can begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the LULC data per sub-area per year\n",
    "for sub_area in sub_areas:\n",
    "    # Access pre-calculated window geometries for the current sub-area\n",
    "    window_geometries = window_geometries_per_sub_area[sub_area]\n",
    "\n",
    "    all_years_data = []\n",
    "\n",
    "    # Iterate through each year's data for the current sub-area\n",
    "    for year, dw_class in tqdm(results_per_area_and_year[sub_area].items(), desc=f\"Processing Years for {sub_area}\"):\n",
    "        aggregated_pixel_counts = defaultdict(int)\n",
    "\n",
    "        # Iterate through each window geometry\n",
    "        for window_geometry in tqdm(window_geometries, desc=f\"Processing Windows for Year {year}\"):\n",
    "            # Perform analysis within this window\n",
    "            pixel_count_stats = dw_class.reduceRegion(\n",
    "                reducer=ee.Reducer.frequencyHistogram(),\n",
    "                geometry=window_geometry,\n",
    "                scale=10,  # Adjust the scale based on your dataset's resolution\n",
    "                maxPixels=1e10\n",
    "            ).getInfo()\n",
    "\n",
    "            # Process the results directly\n",
    "            pixel_counts = pixel_count_stats.get('label_mode', {})\n",
    "            \n",
    "            # Aggregate pixel counts across windows\n",
    "            for key, count in pixel_counts.items():\n",
    "                aggregated_pixel_counts[key] += count\n",
    "\n",
    "        # Map numeric labels to actual class labels if necessary\n",
    "        mapped_keys = {str(i): label for i, label in enumerate(class_labels)}  # Ensure class_labels is defined\n",
    "        pixel_counts_formatted = {mapped_keys.get(key, key): value for key, value in aggregated_pixel_counts.items()}\n",
    "        \n",
    "        all_years_data.append({'Year': year, **pixel_counts_formatted})\n",
    "\n",
    "    # After processing all years for the current sub-area, save to a CSV file\n",
    "    df = pd.DataFrame(all_years_data)\n",
    "    df = df.set_index('Year')\n",
    "    filename = f'C:\\\\Users\\\\grobler\\\\Desktop\\\\Personal\\\\Masters\\\\Data\\\\DW_datasets\\\\{Park}\\\\{Park}_{sub_area}_LULC_from_{starting_year}_to_{ending_year}.csv'\n",
    "    df.to_csv(filename, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data collection of LULC CHANGES over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Collecting & calculating the LULC change (server-side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store LULC change results per sub-area and per year pair\n",
    "results_per_area_and_year_pairs = {}\n",
    "\n",
    "# Assuming 'sub_areas', 'Years', 'Park', and 'geometry' are already defined\n",
    "for sub_area in sub_areas:\n",
    "    # Update the path based on the new structure and sub-area\n",
    "    park_sub_shp = fr'C:\\\\Users\\\\grobler\\\\Desktop\\\\Personal\\\\Masters\\\\Data\\\\GIS\\\\Parks_buffer\\\\sub_areas\\\\{sub_area}\\\\{Park}_{sub_area}.shp'\n",
    "    # It seems there was a mistake in the variable used here; it should be 'park_sub_shp' instead of 'parks_shp'\n",
    "    park_sub = geemap.shp_to_ee(park_sub_shp)\n",
    "    geometry = park_sub.geometry()    \n",
    "\n",
    "    # Initialize a dictionary for this sub-area to store dw_class objects per year\n",
    "    dw_classes_per_year = {}\n",
    "\n",
    "    for Year in Years:\n",
    "        start_date = f'{Year}-01-01'\n",
    "        end_date = f'{Year}-12-31'\n",
    "\n",
    "        # This loads the DW dataset according to parameters set above\n",
    "        dw_classes = geemap.dynamic_world(geometry, start_date, end_date, return_type='class', reducer='mode')\n",
    "        dw_class = dw_classes.clip(geometry)\n",
    "\n",
    "        # Store the dw_class in the dictionary with the year as the key\n",
    "        dw_classes_per_year[Year] = dw_class\n",
    "\n",
    "    # Now calculate LULC changes for each pair of consecutive years within this sub-area\n",
    "    dw_classes_per_year_pairs = defaultdict(dict)\n",
    "    for year_index in range(len(Years) - 1):\n",
    "        pre_year = Years[year_index]\n",
    "        post_year = Years[year_index + 1]\n",
    "\n",
    "        image_pre = dw_classes_per_year[pre_year].select('label_mode')\n",
    "        image_post = dw_classes_per_year[post_year].select('label_mode')\n",
    "\n",
    "        # Combine the two images into a single image encoding transitions\n",
    "        combined = image_pre.multiply(10).add(image_post)\n",
    "\n",
    "        # Store the combined LULC change image for this year pair within the sub-area\n",
    "        dw_classes_per_year_pairs[f\"{pre_year}-{post_year}\"] = combined\n",
    "\n",
    "    # Store the LULC change results for this sub-area\n",
    "    results_per_area_and_year_pairs[sub_area] = dw_classes_per_year_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Populating a csv with the LULC change data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_area in sub_areas:\n",
    "    # Access pre-calculated window geometries for the current sub-area\n",
    "    window_geometries = window_geometries_per_sub_area[sub_area]\n",
    "\n",
    "    yearly_transition_counts = {}\n",
    "\n",
    "    # Iterate through each year pair's data for the current sub-area\n",
    "    for year_pair, dw_class in tqdm(results_per_area_and_year_pairs[sub_area].items(), desc=f\"Processing Year Pairs for {sub_area}\"):\n",
    "        year_pair_transition_counts = defaultdict(int)\n",
    "        pre_year, post_year = year_pair.split('-')\n",
    "\n",
    "        # Iterate through each window geometry\n",
    "        for window_geometry in tqdm(window_geometries, desc=f\"Processing Windows for Year Pair {year_pair}\"):\n",
    "            # Perform analysis within this window\n",
    "            transition_counts = dw_class.reduceRegion(\n",
    "                reducer=ee.Reducer.frequencyHistogram(),\n",
    "                geometry=window_geometry,\n",
    "                scale=10,\n",
    "                maxPixels=1e10\n",
    "            ).getInfo()\n",
    "\n",
    "            transition_counts_dict = transition_counts.get('label_mode', {})\n",
    "\n",
    "            # To create a dictionairy used later on for mapping\n",
    "            transition_label_map = {}\n",
    "\n",
    "            # Map combined values to transition labels and aggregate counts\n",
    "            for i, label_pre in enumerate(class_labels):\n",
    "                for j, label_post in enumerate(class_labels):\n",
    "                    combined_value = str(i * 10 + j)\n",
    "                    transition_label = f\"{label_pre}_to_{label_post}\"\n",
    "                    count = transition_counts_dict.get(combined_value, 0)\n",
    "                    year_pair_transition_counts[transition_label] += count\n",
    "                    transition_label_map[combined_value] = transition_label\n",
    "\n",
    "        # Store the aggregated counts for the current year transition\n",
    "        yearly_transition_counts[f\"{pre_year}_to_{post_year}\"] = year_pair_transition_counts\n",
    "\n",
    "    # Convert the dictionary to a DataFrame for CSV export\n",
    "    df_transitions = pd.DataFrame(yearly_transition_counts).fillna(0).reset_index().rename(columns={'index': 'Change'})\n",
    "\n",
    "    # Reordering columns\n",
    "    ordered_cols = ['Change'] + sorted(df_transitions.columns[1:], key=lambda x: int(x.split('_to_')[0]))\n",
    "    df_transitions = df_transitions[ordered_cols]\n",
    "\n",
    "    # Output location and filename adjustment for each sub-area\n",
    "    out_dir = fr'C:\\Users\\grobler\\Desktop\\Personal\\Masters\\Data\\DW_datasets\\{Park}'\n",
    "    csv_file_path = os.path.join(out_dir, f'{Park}_{sub_area}_LULC_change_from_{starting_year}_to_{ending_year}.csv')\n",
    "\n",
    "    # Export to CSV\n",
    "    df_transitions.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plotting the data collected above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Characterize the buffer zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dissolved buffer zones\n",
    "dissolved_df = pd.read_csv(fr'C:\\\\Users\\\\grobler\\\\Desktop\\\\Personal\\\\Masters\\\\Data\\\\DW_datasets\\\\{Park}\\\\{Park}_Dissolved_LULC_from_{starting_year}_to_{ending_year}.csv', index_col='Year')\n",
    "# Load the additional parks LULC data\n",
    "parks_df = pd.read_csv(fr'C:\\\\Users\\\\grobler\\\\Desktop\\\\Personal\\\\Masters\\\\Data\\\\DW_datasets\\\\{Park}\\\\{Park}_Parks_LULC_from_{starting_year}_to_{ending_year}.csv', index_col='Year')\n",
    "\n",
    "# Assuming 'dw_vis' contains your visualization settings including the palette\n",
    "palette = dw_vis[\"palette\"]\n",
    "\n",
    "# Dynamically filter class_labels to only include columns that exist in dissolved_df or parks_df\n",
    "valid_class_labels = [label for label in class_labels if label in dissolved_df.columns or label in parks_df.columns]\n",
    "\n",
    "# Setup the figure size\n",
    "fig, ax = plt.subplots(figsize=(15, 10))  # Width is now dependent on the number of years\n",
    "\n",
    "# Plot the line graph for the dissolved buffer zones\n",
    "for column in valid_class_labels:\n",
    "    if column in dissolved_df.columns:  # Check if the column exists in dissolved_df\n",
    "        color = palette[class_labels.index(column)]  # Use the index from class_labels to get the correct color\n",
    "        ax.plot(dissolved_df.index, dissolved_df[column], marker='o', linestyle='-', label=column, color=color)\n",
    "\n",
    "# Plot the line graph for the parks LULC with dashed lines\n",
    "for column in valid_class_labels:\n",
    "    if column in parks_df.columns:  # Check if the column exists in parks_df\n",
    "        color = palette[class_labels.index(column)]  # Use the index from class_labels to get the correct color\n",
    "        ax.plot(parks_df.index, parks_df[column], marker='o', linestyle='--', label=f'Park {column}', color=color)\n",
    "\n",
    "# Customize axes and labels\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Pixel count')\n",
    "ax.set_yscale('log')\n",
    "ax.set_title(f\"LULC for {Park}'s park vs. dissolved buffer zone from {starting_year} to {ending_year}\", fontsize=18)\n",
    "ax.legend(title='Class', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.set_xticks(dissolved_df.index)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "# The relative size of the pie charts\n",
    "relative_pie_size = 0.15  # Adjust this as needed for the size of the pie charts\n",
    "\n",
    "# Use the x-ticks from the line graph to align the pie charts\n",
    "xticks = ax.get_xticks()\n",
    "xticks = xticks[(xticks >= dissolved_df.index.min()) & (xticks <= dissolved_df.index.max())]\n",
    "xticks = xticks[:len(dissolved_df.index)]  # Ensure matching length\n",
    "\n",
    "# Fill NaN values in 'dissolved_df' and 'parks_df' with 0\n",
    "dissolved_df = dissolved_df.fillna(0)\n",
    "parks_df = parks_df.fillna(0)\n",
    "\n",
    "# Loop through the years and create pie charts\n",
    "for i, year in enumerate(dissolved_df.index):\n",
    "    # Get the position for the current year's pie chart\n",
    "    pie_x = xticks[i]\n",
    "    \n",
    "    # Convert data coordinates (year) to figure fraction (0-1) coordinates\n",
    "    trans = ax.transData + fig.transFigure.inverted()\n",
    "    pie_x_fig, _ = trans.transform((pie_x, 0))\n",
    "    \n",
    "    # Define the pie chart rectangle\n",
    "    pie_rect = [pie_x_fig - relative_pie_size / 2, 0.1, relative_pie_size, relative_pie_size]\n",
    "    \n",
    "    # Filter the data for this year, ensuring it matches the valid class labels\n",
    "    pie_data = dissolved_df.loc[year, valid_class_labels]\n",
    "    \n",
    "    # Ensure the colors correspond to the correct classes\n",
    "    pie_colors = [palette[class_labels.index(col)] for col in pie_data.index]\n",
    "\n",
    "    # Create a new axis for the pie chart and plot it with percentages\n",
    "    ax_pie = fig.add_axes(pie_rect, frameon=False)\n",
    "    ax_pie.pie(pie_data, colors=pie_colors, startangle=90)\n",
    "\n",
    "# Adjust the layout\n",
    "plt.subplots_adjust(bottom=0.3)  # Adjust this as needed\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Plotting the normalized yearly difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the differences between consecutive years\n",
    "#dissolved_diff = dissolved_df.diff().dropna()\n",
    "#parks_diff = parks_df.diff().dropna()\n",
    "# Calculate the differences between consecutive years\n",
    "dissolved_diff = dissolved_df.diff().fillna(0)\n",
    "parks_diff = parks_df.diff().fillna(0)\n",
    "\n",
    "# Normalize the differences to the maximum absolute value for each LULC class\n",
    "dissolved_diff_normalized = dissolved_diff / dissolved_diff.abs().max()\n",
    "parks_diff_normalized = parks_diff / parks_diff.abs().max()\n",
    "\n",
    "# Filter only the classes that exist in both DataFrames\n",
    "available_classes = [label for label in class_labels if label in dissolved_diff.columns and label in parks_diff.columns]\n",
    "\n",
    "# Determine the number of available classes\n",
    "num_classes = len(available_classes)\n",
    "\n",
    "# Dynamically calculate the number of rows and columns based on the number of available classes\n",
    "ncols = 3\n",
    "nrows = (num_classes + ncols - 1) // ncols  # Calculate the number of rows to fit the available classes\n",
    "\n",
    "# Create the subplots with the calculated number of rows and columns\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(available_classes):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Bar width and position adjustments\n",
    "    width = 0.35\n",
    "    x = np.arange(len(dissolved_diff.index))\n",
    "    \n",
    "    # Plot for dissolved buffer zones\n",
    "    color = palette[class_labels.index(column)]  # Ensure color consistency\n",
    "    ax.bar(x - width/2, dissolved_diff_normalized[column], width, label=f'Dissolved {column}', color=color)\n",
    "    \n",
    "    # Plot for parks with dashed edge\n",
    "    ax.bar(x + width/2, parks_diff_normalized[column], width, label=f'Park {column}', color='none', edgecolor=color, linestyle='--', hatch='//')\n",
    "    \n",
    "    # Set axis properties\n",
    "    ax.set_title(column)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(dissolved_diff.index, rotation=45)\n",
    "    ax.set_ylim(-1.1, 1.1)  # Set y-axis limits to -1 and 1\n",
    "    ax.legend()\n",
    "    ax.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "# Remove any empty subplots (if applicable)\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.suptitle(f\"Normalized yearly difference in LULC for {Park}'s park vs. dissolved buffer zone from {starting_year} to {ending_year}\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Plotting the LULCC on Sankey diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Prepare the data in Sankey format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dissolved buffer zones\n",
    "dissolved_change_df = pd.read_csv(fr'C:\\\\Users\\\\grobler\\\\Desktop\\\\Personal\\\\Masters\\\\Data\\\\DW_datasets\\\\{Park}\\\\{Park}_Dissolved_LULC_change_from_{starting_year}_to_{ending_year}.csv', index_col='Change')\n",
    "\n",
    "# Initialize lists to store the source, target, and values for the Sankey diagram\n",
    "sources = []\n",
    "targets = []\n",
    "values = []\n",
    "\n",
    "# Number of class labels\n",
    "num_labels = len(class_labels)\n",
    "\n",
    "# Generate sources, targets, and values from the DataFrame\n",
    "for col in dissolved_change_df.columns:\n",
    "    from_year, to_year = col.split('_to_')\n",
    "    for index, value in dissolved_change_df[col].items():\n",
    "        if value > 0:  # Only create a link if there's a non-zero value\n",
    "            from_class, to_class = index.split('_to_')\n",
    "            source_index = (int(from_year) - starting_year) * num_labels + class_labels.index(from_class)\n",
    "            target_index = (int(to_year) - starting_year) * num_labels + class_labels.index(to_class)\n",
    "            sources.append(source_index)\n",
    "            targets.append(target_index)\n",
    "            values.append(value)\n",
    "\n",
    "# Define node labels and colors (repeated for each year)\n",
    "node_labels = [f'{label}' for year in range(starting_year, ending_year + 1) for label in class_labels]\n",
    "node_colors = palette * (ending_year - starting_year + 1)  # Ensure each node has a color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Plot the Sankey-diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sankey diagram\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=node_labels,\n",
    "        color=node_colors\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=sources,\n",
    "        target=targets,\n",
    "        value=values\n",
    "    ))])\n",
    "\n",
    "# Calculate the proportional positions of the year annotations along the x-axis\n",
    "year_positions = {year: (year - starting_year) / (ending_year - starting_year) for year in range(starting_year, ending_year + 1)}\n",
    "\n",
    "# Update layout to add year annotations below the diagram\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=f\"LULC change for {Park}'s dissolved buffer zone from {starting_year} to {ending_year}\",\n",
    "        font=dict(size=20)  # Here you can adjust the size of the title\n",
    "    ),\n",
    "    font=dict(size=10),  # Adjusts the global font size used in the diagram\n",
    "    annotations=[dict(\n",
    "        showarrow=False,\n",
    "        text=str(year),  # Year label\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        x=year_positions[year],  # Updated x position for each year\n",
    "        y=-0.1,\n",
    "        align=\"center\",\n",
    "        font=dict(size=10)  # This adjusts the annotation text size\n",
    "    ) for year in range(starting_year, ending_year + 1)],\n",
    "    height=600  # Adjust the height as needed for your diagram\n",
    ")\n",
    "\n",
    "# Disable the x and y axes (since we have our custom annotations for years)\n",
    "#fig.update_xaxes(visible=False)\n",
    "#fig.update_yaxes(visible=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate the LULCC intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Choose sub-area for further investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Dropdown Widget\n",
    "sub_area_dropdown = widgets.Dropdown(\n",
    "    options=sub_areas,\n",
    "    value='Dissolved',\n",
    "    description='Buffer sub-area for further investigation:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Create a Variable\n",
    "inv_sub_area = sub_area_dropdown.value\n",
    "\n",
    "# Define an Update Function\n",
    "def inv_sub_area_change(change):\n",
    "    global inv_sub_area\n",
    "    inv_sub_area = change.new\n",
    "    print(f\"Buffer sub-area to investigate changed to: {inv_sub_area}\")\n",
    "\n",
    "# Attach the Update Function to the Dropdown\n",
    "sub_area_dropdown.observe(inv_sub_area_change, names='value')\n",
    "\n",
    "#Print note to user\n",
    "print('Note: Recommened to start with \"Disolved\" (standard setting) first and then move on to other options as deemed necessairy.\\n\\nCPA: Catchment Protected Area, VPA: Viewshed Protected Area, PNA: Priority Natural Areas, Parks: Park boundaries themselves')\n",
    "\n",
    "# To display the dropdown in a Jupyter notebook\n",
    "display(sub_area_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Prepare data in \"cross-tabulation matrix\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the respective sub-area for further investigation\n",
    "df = pd.read_csv(fr'C:\\Users\\grobler\\Desktop\\Personal\\Masters\\Data\\DW_datasets\\{Park}\\{Park}_{sub_area_dropdown.value}_LULC_change_from_{starting_year}_to_{ending_year}.csv')\n",
    "\n",
    "# The CSV has transitions labeled as 'from_to'. We need to split these into two separate columns for pivot.\n",
    "df[['from', 'to']] = df['Change'].str.split('_to_', expand=True)\n",
    "\n",
    "# Initialize an empty dictionary to hold the transition matrices\n",
    "transition_matrices = {}\n",
    "\n",
    "for year in df.columns[1:-2]:  # Skips the first column and the last two columns, assuming the first columns is 'Change' and the last two are 'from' and 'to'\n",
    "    # Pivot the full table to create a matrix for the current year transition\n",
    "    matrix = df.pivot(index='from', columns='to', values=year).fillna(0)\n",
    "\n",
    "    # Since we're going to add this as a new row, we need to transpose the matrix first, add the row, then transpose back\n",
    "    matrix = matrix.T\n",
    "    # Calculate 'Final total' - sum of the columns in the matrix\n",
    "    matrix['Final total'] = matrix.sum(axis=1)\n",
    "    # Calculate 'Gross gain' - 'Final total' - class==class\n",
    "    matrix['Gross gain'] = matrix['Final total'] - [matrix.at[state, state] if state in matrix.columns else 0 for state in matrix.index]\n",
    "    #Flip the table back now that 'Final total' and 'Gross gain' was calculated\n",
    "    matrix = matrix.T\n",
    "\n",
    "    # Calculate 'Initial total' - sum of the rows in the matrix\n",
    "    matrix['Initial total'] = matrix.sum(axis=1)\n",
    "    # Calculate 'Gross gain' - 'Initial total' - class==class\n",
    "    matrix['Gross loss'] = matrix['Initial total'] - [matrix.at[state, state] if state in matrix.columns else 0 for state in matrix.index]\n",
    "\n",
    "    #Populate the dictionary\n",
    "    transition_matrices[year] = matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Calcualte the \"Time Intensity\" of LULCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1. \"Time Intensity\" calculation (St & U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to hold the calculated values\n",
    "time_intervals = []\n",
    "annual_rates_of_change = []\n",
    "\n",
    "# Loop through each year interval\n",
    "for year_interval, matrix in transition_matrices.items():\n",
    "    # Retrieve the total area of change for the interval\n",
    "    total_area_of_change = matrix['Gross loss']['Gross gain']\n",
    "    # Retrieve the total area of the study area\n",
    "    total_area_of_study_region = matrix['Initial total']['Final total']\n",
    "    # Assume a duration of the interval in years of 1 for simplicity\n",
    "    duration_of_interval = 1\n",
    "    # Calculate the annual rate of change (time intensity)\n",
    "    time_intensity = (total_area_of_change / total_area_of_study_region) / duration_of_interval * 100\n",
    "    \n",
    "    # Store the results\n",
    "    time_intervals.append(year_interval)\n",
    "    annual_rates_of_change.append(time_intensity)\n",
    "\n",
    "# Calculate the uniform intensity value across all intervals\n",
    "total_change_over_all_intervals = sum([matrix['Gross loss']['Gross gain'] for matrix in transition_matrices.values()])\n",
    "#total_area_of_study_region_all_intervals = sum([matrix['Initial total']['Final total'] for matrix in transition_matrices.values()])\n",
    "total_time = len(time_intervals)\n",
    "uniform_intensity = (total_change_over_all_intervals / total_area_of_study_region) / total_time * 100\n",
    "\n",
    "# Initialize significant_intervals to None\n",
    "significant_intervals = None\n",
    "# Only update significant_intervals if inv_sub_area is 'Dissolved'\n",
    "if significant_intervals is None or inv_sub_area == 'Dissolved':\n",
    "    # Find the years for which the annual_rates_of_change > uniform_intensity\n",
    "    # This is to be used in all plots following this initial time intensity analysis\n",
    "    significant_intervals = [year for year, rate in zip(time_intervals, annual_rates_of_change) if rate > uniform_intensity]\n",
    "\n",
    "print(significant_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#significant_intervals = ['2016_to_2017', '2021_to_2022']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2. \"Time Intensity\" plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the annual rates of change\n",
    "plt.barh(time_intervals, annual_rates_of_change, color='gray', edgecolor='black')\n",
    "\n",
    "# Plot the uniform intensity value\n",
    "plt.axvline(x=uniform_intensity, color='red', linestyle='--', label=f'{uniform_intensity:.2f} = Uniform Intensity')\n",
    "# Add 'Slow' and 'Fast' labels relative to the uniform line\n",
    "plt.text(uniform_intensity - 0.08, 5.7, 'Slow', verticalalignment='center', horizontalalignment='right', color='red', fontsize=12)\n",
    "plt.text(uniform_intensity + 0.08, 5.7, 'Fast', verticalalignment='center', horizontalalignment='left', color='red', fontsize=12)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Annual Change Area (percent of map)')\n",
    "plt.ylabel('Time interval')\n",
    "plt.title(f\"LULCC time intensity analysis for {Park}'s {inv_sub_area} buffer zone\", fontsize=15)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Calcualte the \"Category Intensity\" of LULCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1. \"Category Intensity\" calculation (Gtj & Lti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: the code is currently developed to only analyse those years with St > U indetified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to hold category intensities for the significant intervals\n",
    "category_intensities = {}\n",
    "\n",
    "# For each significant year, calculate the category gain intensities\n",
    "for year in significant_intervals:\n",
    "    # Get the transition matrix for the current year\n",
    "    matrix = transition_matrices[year]\n",
    "    \n",
    "    # Initialize a dictionary to store loss and gain intensities for the current year\n",
    "    loss_intensities = {}\n",
    "    gain_intensities = {}\n",
    "    \n",
    "    # Loop through the categories in the matrix\n",
    "    for category in matrix.index[:-2]:  # Exclude 'Final total' and 'Gross gain' rows\n",
    "        initial_total = matrix.at[category, 'Initial total']\n",
    "        final_total = matrix.T.at[category, 'Final total']\n",
    "        gross_loss = matrix.at[category, 'Gross loss']\n",
    "        gross_gain = matrix.T.at[category, 'Gross gain']\n",
    "        \n",
    "        # Calculate loss intensity\n",
    "        if initial_total > 0:\n",
    "            loss_intensity = (gross_loss / duration_of_interval) / initial_total * 100\n",
    "            loss_intensities[category] = loss_intensity\n",
    "        \n",
    "        # Calculate gain intensity\n",
    "        if final_total > 0:\n",
    "            gain_intensity = (gross_gain / duration_of_interval) / final_total * 100\n",
    "            gain_intensities[category] = gain_intensity\n",
    "    \n",
    "    # Store the intensities for the current year\n",
    "    category_intensities[year] = {\n",
    "        'loss_intensities': loss_intensities,\n",
    "        'gain_intensities': gain_intensities\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2. \"Category Intensity\" plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the total number of categories\n",
    "total_categories = 9\n",
    "\n",
    "# Loop over each significant interval to plot their data\n",
    "for interval in significant_intervals:\n",
    "    # Get the data for the current interval\n",
    "    data = category_intensities[interval]\n",
    "\n",
    "    # Extract existing categories, but fill in missing ones with 0s\n",
    "    categories = list(data['loss_intensities'].keys())  # Get the list of available categories\n",
    "    loss_intensities = [data['loss_intensities'].get(cat, 0) for cat in categories]\n",
    "    gain_intensities = [data['gain_intensities'].get(cat, 0) for cat in categories]\n",
    "\n",
    "    # Padding with zeros for intensities but leave labels empty\n",
    "    empty_slots = total_categories - len(categories)\n",
    "    loss_intensities += [0] * empty_slots\n",
    "    gain_intensities += [0] * empty_slots\n",
    "    # Pad categories with empty strings for the labels\n",
    "    categories += [''] * empty_slots\n",
    "\n",
    "    # Find the index of the interval to get the annual rate of change\n",
    "    index = time_intervals.index(interval)\n",
    "    # Get the specific uniform intensity for this interval\n",
    "    specific_uniform_intensity = annual_rates_of_change[index]\n",
    "\n",
    "    # Position of bars on the y-axis\n",
    "    y_pos = np.arange(total_categories)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Create horizontal bars for losses\n",
    "    plt.barh(y_pos, loss_intensities, color='tomato', edgecolor='black', height=0.4, label='Loss Intensity')\n",
    "\n",
    "    # Create horizontal bars for gains, slightly offset on the y-axis\n",
    "    plt.barh(y_pos + 0.4, gain_intensities, color='mediumseagreen', edgecolor='black', height=0.4, label='Gain Intensity')\n",
    "\n",
    "    # Draw a dashed line for the uniform intensity\n",
    "    plt.axvline(x=specific_uniform_intensity, color='black', linestyle='--', label=f'Uniform Intensity {specific_uniform_intensity:.2f}%')\n",
    "    # Add 'Dormant' and 'Active' labels relative to the uniform line\n",
    "    plt.text(specific_uniform_intensity - 0.25, +8.8, 'Dormant', verticalalignment='center', horizontalalignment='right', color='black', fontsize=10)\n",
    "    plt.text(specific_uniform_intensity + 0.5, +8.8, 'Active', verticalalignment='center', horizontalalignment='left', color='black', fontsize=10)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Annual Change Intensity (percent of category)')\n",
    "    plt.title(f\"LULCC category intensity analysis for {Park}'s {inv_sub_area} buffer zone from {interval}\", fontsize=13)\n",
    "    plt.yticks(y_pos + 0.2, categories)  # Set y-ticks to be in the middle of the two bars, leaving empty labels for missing categories\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is purely for writing purposes (can copy this output into thesis)\n",
    "# Prepare an empty list to collect data\n",
    "#summary_data = []\n",
    "\n",
    "# Loop over each significant interval for printing summaries in a table\n",
    "#for interval in significant_intervals:\n",
    "    # Get the data for the current interval\n",
    "#    data = category_intensities[interval]\n",
    "#    categories = list(data['loss_intensities'].keys())\n",
    "#    loss_intensities = [data['loss_intensities'][cat] for cat in categories]\n",
    "#    gain_intensities = [data['gain_intensities'].get(cat, 0) for cat in categories]\n",
    "\n",
    "#    index = time_intervals.index(interval)\n",
    "#    specific_uniform_intensity = annual_rates_of_change[index]\n",
    "\n",
    "    # Collect data for the DataFrame only if the intensities are above the uniform intensity\n",
    "#    for cat, loss, gain in zip(categories, loss_intensities, gain_intensities):\n",
    "#        if loss > specific_uniform_intensity or gain > specific_uniform_intensity:\n",
    "#            summary_data.append({\n",
    "#                'Interval': interval,\n",
    "#                'Category': cat,\n",
    "#                'Loss Intensity (%)': loss,\n",
    "#                'Gain Intensity (%)': gain,\n",
    "#                'Uniform Intensity (%)': f\"{specific_uniform_intensity:.2f}\",\n",
    "                #'Loss > Uniform': loss > specific_uniform_intensity,\n",
    "                #'Gain > Uniform': gain > specific_uniform_intensity\n",
    "#            })\n",
    "\n",
    "# Create DataFrame\n",
    "#summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "#summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Calcualte the \"Transition Intensity\" of LULCC (Qtmj, Vtm, Rtin and Wtn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1. \"Transition Intensity\" calculation for Qtmj, Vtm -> Loss, transition from target category to all other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to hold category transition intensities for the significant intervals\n",
    "category_transitions = {}\n",
    "\n",
    "for year in significant_intervals:\n",
    "    matrix = transition_matrices[year]\n",
    "\n",
    "    # Correcting the approach to access 'Final total' from the rows, not the columns\n",
    "    # Also, ensuring we sum the correct elements for 'total_area_non_m'\n",
    "    final_totals = matrix.loc['Final total'][:-2]  # Assuming 'Final total' and 'Gross gain' are at the end\n",
    "    total_area = final_totals.sum()\n",
    "\n",
    "    # Initialize a matrix to store transition intensities for the current year, including a column for uniform intensity\n",
    "    transition_intensities = pd.DataFrame(0, index=matrix.index[:-2], columns=matrix.columns[:-2].append(pd.Index(['Uniform_Intensity'])))\n",
    "\n",
    "    for category_from in matrix.index[:-2]:  # Exclude 'Final total' and 'Gross gain' rows\n",
    "        gross_loss = matrix.loc[category_from, 'Gross loss']\n",
    "        area_not_m = total_area - matrix.loc['Final total', category_from]\n",
    "        \n",
    "        if area_not_m > 0:  # Avoid division by zero\n",
    "            uniform_intensity = (gross_loss / duration_of_interval) / area_not_m * 100\n",
    "            transition_intensities.loc[category_from, 'Uniform_Intensity'] = uniform_intensity\n",
    "\n",
    "        for category_to in matrix.columns[:-2]:  # Exclude 'Initial total' and 'Gross loss' columns\n",
    "            if category_from != category_to:  # Ensure transitions between different categories\n",
    "                transition_area = matrix.loc[category_from, category_to]\n",
    "                final_total_category_to = matrix.loc['Final total', category_to]\n",
    "                \n",
    "                if final_total_category_to > 0:  # Avoid division by zero\n",
    "                    transition_intensity = (transition_area / duration_of_interval) / final_total_category_to * 100\n",
    "                    transition_intensities.at[category_from, category_to] = transition_intensity\n",
    "\n",
    "    category_transitions[year] = transition_intensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2. \"Transition Intensity\" plots for Qtmj, Vtm -> Loss, transition from target category to all other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in significant_intervals:\n",
    "    matrix_to_plot = category_transitions[year]\n",
    "    \n",
    "    # Rounding the matrix values\n",
    "    matrix_to_plot = matrix_to_plot.round(0)\n",
    "    \n",
    "    # Update the mask for the new shape\n",
    "    mask = np.zeros_like(matrix_to_plot, dtype=bool)\n",
    "    np.fill_diagonal(mask, True)  # Continue to hide diagonal values\n",
    "\n",
    "    # Setting the colors for the mask\n",
    "    cmap = mpl.colormaps.get_cmap('Greens')\n",
    "    cmap.set_bad(\"white\")  # setting background for masked elements\n",
    "    \n",
    "    # Plot heatmap with updated settings\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    ax = sns.heatmap(matrix_to_plot, annot=True, fmt=\".0f\", cmap=cmap, linewidths=.5, mask=mask)\n",
    "    \n",
    "    # Add vertical lines\n",
    "    for i in range(matrix_to_plot.shape[1] + 1):  # adding lines at each column edge\n",
    "        plt.axvline(x=i, color='black', linestyle='-', linewidth=1)\n",
    "    \n",
    "    plt.title(f\"LULC transition intensity analysis for {Park}'s {inv_sub_area} buffer zone from {year}\", fontsize=14)\n",
    "    plt.xlabel('To Category & Uniform Intensity (percent of category)')\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel('From Category (percent of category)')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################Clarify in the hadings the difference between Rtin and Qtmj#################################################\n",
    "#From trees to flooded vegetation\n",
    "#Qtmj=((matrix)/duration)/final total)*100\n",
    "#((3729.000000/1)/18381.996078)*100\n",
    "#Vtm=((Gross loss/1)/(Final total - class final total))*100\n",
    "#((1.043251e+06/1)/(6.427637e+07-2.677706e+07))*100\n",
    "#Rtin=((matrix)/duration)/initial total)*100\n",
    "#((3.135244e+06/1)/8.137387e+06)*100\n",
    "#Wtn=((Gross gain/1)/(Initial total - class initial total))*100\n",
    "#((4.356936e+06/1)/(6.427637e+07-2.017387e+07))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3. \"Transition Intensity\" calculation for Rtin, Wtn -> Gain, transition to target category from all other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to hold category transition intensities for the significant intervals\n",
    "category_transitions = {}\n",
    "\n",
    "for year in significant_intervals:\n",
    "    matrix = transition_matrices[year]\n",
    "\n",
    "    # Access initial totals from the column directly\n",
    "    initial_totals = matrix['Initial total'][:-2]  # Excluding the last row which is 'Gross gain'\n",
    "    total_area = initial_totals.sum()\n",
    "\n",
    "    # Create DataFrame to store transition intensities\n",
    "    # Exclude 'Initial total' and 'Gross loss' from columns, and 'Final total' and 'Gross gain' from rows\n",
    "    transition_intensities = pd.DataFrame(0, index=matrix.index[:-2], columns=matrix.columns[:-2].append(pd.Index(['Uniform_Intensity'])))\n",
    "\n",
    "    for category_from in matrix.index[:-2]:  # Excluding 'Final total' and 'Gross gain' rows\n",
    "        gross_gain = matrix.loc['Gross gain', category_from]\n",
    "        area_not_n = total_area - matrix.loc[category_from, 'Initial total']\n",
    "        \n",
    "        if area_not_n > 0:\n",
    "            uniform_intensity = (gross_gain / duration_of_interval) / area_not_n * 100\n",
    "            transition_intensities.loc[category_from, 'Uniform_Intensity'] = uniform_intensity\n",
    "\n",
    "        for category_to in matrix.columns[:-2]:  # Excluding 'Initial total' and 'Gross loss'\n",
    "            if category_from != category_to:     # Ensure transitions between different categories\n",
    "                transition_area = matrix.loc[category_from, category_to]\n",
    "                initial_total_category_from = matrix.loc[category_from, 'Initial total']  # Using the source category's initial total\n",
    "        \n",
    "                if initial_total_category_from > 0:\n",
    "                    transition_intensity = (transition_area / duration_of_interval) / initial_total_category_from * 100\n",
    "                    transition_intensities.at[category_from, category_to] = transition_intensity\n",
    "\n",
    "    # Extract the 'Uniform_Intensity' column as a separate Series\n",
    "    uniform_intensity_row = transition_intensities['Uniform_Intensity'].copy()\n",
    "\n",
    "    # Remove the 'Uniform_Intensity' column from its original place\n",
    "    transition_intensities.drop('Uniform_Intensity', axis=1, inplace=True)\n",
    "\n",
    "    # Append the 'Uniform_Intensity' Series as a row to the DataFrame\n",
    "    transition_intensities.loc['Uniform_Intensity'] = uniform_intensity_row\n",
    "\n",
    "    # Store the transition intensities matrix in the dictionary\n",
    "    category_transitions[year] = transition_intensities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.4. \"Transition Intensity\" plots for Rtin, Wtn -> Gain, transition to target category from all other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in significant_intervals:\n",
    "    matrix_to_plot = category_transitions[year]\n",
    "    \n",
    "    # Rounding the matrix values\n",
    "    matrix_to_plot = matrix_to_plot.round(0)\n",
    "    \n",
    "    # Update the mask for the new shape\n",
    "    mask = np.zeros_like(matrix_to_plot, dtype=bool)\n",
    "    np.fill_diagonal(mask, True)  # Continue to hide diagonal values\n",
    "\n",
    "    # Setting the colors for the mask\n",
    "    cmap = mpl.colormaps.get_cmap('Reds')\n",
    "    cmap.set_bad(\"white\")  # setting background for masked elements\n",
    "    \n",
    "    # Plot heatmap with updated settings\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    ax = sns.heatmap(matrix_to_plot, annot=True, fmt=\".0f\", cmap=cmap, linewidths=.5, mask=mask)\n",
    "    \n",
    "    # Add horizontal lines\n",
    "    for i in range(matrix_to_plot.shape[0] + 1):  # adding lines at each row edge\n",
    "        plt.axhline(y=i, color='black', linestyle='-', linewidth=1)\n",
    "    \n",
    "    plt.title(f\"LULC transition intensity analysis for {Park}'s {inv_sub_area} buffer zone from {year}\", fontsize=14)\n",
    "    plt.xlabel('To Category (percent of category)')\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel('From Category & Uniform Intensity (percent of category)')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is purely for writing purposes (can copy this output into thesis)\n",
    "# Prepare an empty list to collect data for transition intensities\n",
    "#transition_summary_data = []\n",
    "\n",
    "# Loop over each significant interval to analyze transition intensities\n",
    "#for interval in significant_intervals:\n",
    "    # Access the precomputed transition intensities matrix for this interval\n",
    "#    transition_matrix = category_transitions[interval]\n",
    "#    uniform_intensities = transition_matrix['Uniform_Intensity']\n",
    "\n",
    "    # Loop through each 'from' category (exclude 'Uniform_Intensity' from columns)\n",
    "#    for from_category in transition_matrix.index:\n",
    "#        uniform_intensity = uniform_intensities[from_category]\n",
    "\n",
    "        # Loop through each 'to' category\n",
    "#        for to_category in transition_matrix.columns[:-1]:  # Exclude the last column which is 'Uniform_Intensity'\n",
    "#            if from_category != to_category:  # Ensure we're looking at transitions between different categories\n",
    "#                transition_intensity = transition_matrix.at[from_category, to_category]\n",
    "\n",
    "                # Check if the transition intensity is greater than the uniform intensity\n",
    "#                if transition_intensity > uniform_intensity:\n",
    "#                    transition_summary_data.append({\n",
    "#                        'Interval': interval,\n",
    "#                        'From Category': from_category,\n",
    "#                        'To Category': to_category,\n",
    "#                        'Transition Intensity (%)': transition_intensity,\n",
    "#                        'Uniform Intensity (%)': uniform_intensity\n",
    "#                    })\n",
    "\n",
    "# Create DataFrame from collected data\n",
    "#transition_summary_df = pd.DataFrame(transition_summary_data)\n",
    "\n",
    "# Set the display options to show all rows if desired\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display the DataFrame\n",
    "#display(transition_summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plot the change hotspots for two years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Choose year interval to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_opions = significant_intervals + ['Choose here...']\n",
    "\n",
    "# Define the Dropdowns for selecting the starting and ending years\n",
    "pre_post_year_dropdown = widgets.Dropdown(\n",
    "    options=year_opions,\n",
    "    value='Choose here...',\n",
    "    description='Year interval of interest:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Initialize Variables\n",
    "pre_post_year = pre_post_year_dropdown.value\n",
    "\n",
    "# Define Update Functions for each variable\n",
    "def on_pre_post_year_change(change):\n",
    "    global pre_post_year\n",
    "    pre_post_year = change.new\n",
    "    print(f\"Pre- and Post year of investigation updated to: {pre_post_year}\")\n",
    "\n",
    "\n",
    "# Attach the Update Functions to the respective Dropdowns\n",
    "pre_post_year_dropdown.observe(on_pre_post_year_change, names='value')\n",
    "\n",
    "# To display the dropdown in a Jupyter notebook\n",
    "display(pre_post_year_dropdown)\n",
    "\n",
    "#Note on how to use the multiple select tool\n",
    "print('Note: To effectively use the widget below use \"ctrl/cmd\" on the kyboard to select multiple')\n",
    "\n",
    "# Create a multi-select widget for the transition labels\n",
    "select_widget = widgets.SelectMultiple(\n",
    "    options=list(transition_label_map.values()),  # Display labels for selection\n",
    "    value=[],  # Default value, no selection\n",
    "    description='Active Changes',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='350px', height='300px')\n",
    ")\n",
    "\n",
    "display(select_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Set variables based on selections above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the format of the years based on selection above\n",
    "inv_year_range = pre_post_year.replace('_to_', '-')\n",
    "\n",
    "# Example to map selected labels back to their keys\n",
    "selected_labels = select_widget.value  # This will be a tuple of selected label strings\n",
    "selected_keys = [key for key, value in transition_label_map.items() if value in selected_labels]\n",
    "\n",
    "# Convert selected keys to integers, as they are stored as strings in transition_label_map\n",
    "transitions_of_interest = list(map(int, selected_keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Show the spatial extent of these changes on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 'combined' for the map\n",
    "combined = results_per_area_and_year_pairs[inv_sub_area][inv_year_range]\n",
    "\n",
    "# Start with a condition that's always False\n",
    "mask = ee.Image(0)\n",
    "\n",
    "# Dynamically update the mask based on selected transitions\n",
    "for transition in transitions_of_interest:\n",
    "    mask = mask.Or(combined.eq(transition))\n",
    "\n",
    "filtered_transitions = combined.updateMask(mask)\n",
    "\n",
    "# Define visualization parameters with all red colors as per your request\n",
    "vis_params = {\n",
    "    'min': 0,\n",
    "    'max': max(transitions_of_interest),  # Adjust max based on your data\n",
    "    'palette': ['red'] * len(transitions_of_interest)\n",
    "}\n",
    "\n",
    "# To initiate map\n",
    "Map = geemap.Map(basemap='Esri.WorldImagery')\n",
    "\n",
    "# Use geemap to display the map with filtered transitions\n",
    "Map.addLayer(filtered_transitions, vis_params, 'Filtered Transitions')\n",
    "\n",
    "# To initiate display of map\n",
    "display(Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## END ###################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
